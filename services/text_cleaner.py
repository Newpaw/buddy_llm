import asyncio
from bs4 import BeautifulSoup
import re
from concurrent.futures import ThreadPoolExecutor
import unicodedata
import emoji
from urllib.parse import urlparse

# Funkce pro odstran캩n칤 emoji pomoc칤 demojize a regex
def remove_emoji(text):
    '''
    Remove all emojis from the input text using the emoji library's demojize function.
    '''
    demojized_text = emoji.demojize(text)
    clean_text = re.sub(r':[^:\s]+:', '', demojized_text)
    return clean_text

def normalize_unicode(text):
    '''
    Normalize Unicode characters in the input text to their canonical form.
    '''
    return unicodedata.normalize('NFKC', text)

def extract_domain(url):
    '''
    Extract the first and second level domain from a URL.
    
    Args:
        url (str): The URL to extract the domain from.
    
    Returns:
        str: The extracted domain (e.g., 'o2.cz').
    '''
    try:
        parsed_url = urlparse(url)
        hostname = parsed_url.hostname
        if not hostname:
            # Pokud URL neobsahuje sch칠ma, zkuste p콏idat 'http://' a znovu analyzovat
            parsed_url = urlparse('http://' + url)
            hostname = parsed_url.hostname
            if not hostname:
                return url  # Pokud st치le nem콢쬰me z칤skat hostname, vra콘te p콢vodn칤 text

        parts = hostname.split('.')
        if len(parts) >= 2:
            return '.'.join(parts[-2:])  # Z칤sk치n칤 posledn칤ch dvou 캜치st칤 dom칠ny
        else:
            return hostname  # Pokud dom칠na nem치 dostatek 캜치st칤, vra콘te ji celou
    except Exception as e:
        # V p콏칤pad캩 chyby vr치t칤me p콢vodn칤 text
        return url

def clean_response_sync(text: str):
    '''
    Clean the input text by removing HTML tags, URLs (replaced by their domains), emojis, unwanted characters, and expanding abbreviations.
    
    Args:
        text (str): The input text to be cleaned.
    
    Returns:
        str: The cleaned text.
    '''

    # 1. Odstran캩n칤 HTML tag콢
    soup = BeautifulSoup(text, "html.parser")
    cleaned_text = soup.get_text()

    # 2. Odstran캩n칤 Markdown odkaz콢 [text](url) a zachov치n칤 pouze textu
    cleaned_text = re.sub(r'\[([^\]]+)\]\((https?://[^\)]+)\)', r'\1', cleaned_text)

    # 3. Odstran캩n칤 z치vorek obsahuj칤c칤ch URL, nap콏. [https://o2.cz]
    # Tento krok odstran칤 cel칠 obsah z치vorek, pokud obsahuje URL
    cleaned_text = re.sub(r'\[(https?://\S+|www\.\S+)\]', '', cleaned_text)

    # 4. Nahrazen칤 캜ist칳ch URL (http, https, www) jejich dom칠nami
    def replace_url_with_domain(match):
        url = match.group(0)
        domain = extract_domain(url)
        return domain

    url_pattern = re.compile(r'(https?://\S+|www\.\S+)')
    cleaned_text = url_pattern.sub(replace_url_with_domain, cleaned_text)

    # 5. Odstran캩n칤 zb칳vaj칤c칤ch z치vorek (parentheses, curly braces, square brackets)
    cleaned_text = re.sub(r'\(.*?\)|\{.*?\}|\[.*?\]', '', cleaned_text)

    # 6. Odstran캩n칤 ne쮂멳ouc칤ch speci치ln칤ch znak콢, ale ponech치n칤 z치kladn칤 interpunkce
    cleaned_text = re.sub(r'[^\w\s.,!?]', '', cleaned_text)

    # 7. Odstran캩n칤 emoji
    cleaned_text = remove_emoji(cleaned_text)

    # 8. Normalizace Unicode znak콢
    cleaned_text = normalize_unicode(cleaned_text)

    # 9. Odstran캩n칤 nadbyte캜n칳ch mezer a o콏ez치n칤 textu
    cleaned_text = re.sub(r'\s+', ' ', cleaned_text).strip()

    # 10. Nahrazen칤 v칤cen치sobn칳ch interpunk캜n칤ch znam칠nek jedn칤m
    cleaned_text = re.sub(r'\.{2,}', '.', cleaned_text)
    cleaned_text = re.sub(r'\!{2,}', '!', cleaned_text)
    cleaned_text = re.sub(r'\?{2,}', '?', cleaned_text)

    # 11. Roz코칤콏en칤 zkratek
    abbreviations = {
        "nap콏.": "nap콏칤klad",
        "atd.": "a tak d치le",
        "ap.": "aproximativn캩",
        "K캜" : "korun",
        "O2" : "ou two"  
    }
    for abbr, full in abbreviations.items():
        cleaned_text = re.sub(r'\b' + re.escape(abbr) + r'\b', full, cleaned_text)

    return cleaned_text

# Asynchronn칤 obal pro 캜i코t캩n칤 odpov캩di
async def clean_response_async(text):
    '''
        Asynchronously clean the input text by running the clean_response_sync function in a thread pool.
    '''
    loop = asyncio.get_event_loop()
    with ThreadPoolExecutor() as pool:
        return await loop.run_in_executor(pool, clean_response_sync, text)

# P콏칤klad pou쬴t칤
#if __name__ == "__main__":
#    sample_texts = [
#        "https://o2.cz",
#        "Nav코tivte na코i str치nku https://o2.cz pro v칤ce informac칤.",
#        "Zkontrolujte www.o2.cz a kontaktujte n치s!",
#        "Toto je text bez URL.",
#        "Emojis 游땕 a URL https://www.example.com/test?param=1",
#        "[https://o2.cz] ap.",
#        "Dal코칤 URL: http://subdomain.example.co.uk/path",
#        "[www.example.com] atd.",
#        "Text p콏ed [https://o2.cz] a text za."
#    ]
#    
#    for sample_text in sample_texts:
#        cleaned = asyncio.run(clean_response_async(sample_text))
#        print(f"P콢vodn칤 text: '{sample_text}'")
#        print(f"캛ist칳 text: '{cleaned}'\n")
